{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c9c5c5",
   "metadata": {},
   "source": [
    "## Detecció automatitzada de defectes en teixits tècnics mitjançant visió artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2bb28",
   "metadata": {},
   "source": [
    "### 1. Preparació de les dades\n",
    "Carregar les imatges i crear còpies de la classe minoritària per equilibrar les dades entre les dues classes. Després, es realitza una divisió entre conjunt d'entrenament i conjunt de validació (80% - 20%) mitjançant la funció splitfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import splitfolders \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionResNetV2, InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_incep\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobile\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af881eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_defecte = \"dataset_job1/1_defecte\"\n",
    "dir_no_defecte = \"dataset_job1/0_nodefecte\"\n",
    "\n",
    "n_defecte = len(os.listdir(dir_defecte))\n",
    "n_no_defecte = len(os.listdir(dir_no_defecte))\n",
    "print(f\"Defecte: {n_defecte}, No defecte: {n_no_defecte}\")\n",
    "\n",
    "# Quantes imatges calen per equilibrar\n",
    "n_extra = n_defecte - n_no_defecte\n",
    "\n",
    "# Llistar imatges de la classe minoritària\n",
    "imatges = os.listdir(dir_no_defecte)\n",
    "\n",
    "# Crear còpies\n",
    "for i in range(n_extra):\n",
    "    imatge_original = random.choice(imatges)\n",
    "    nom_nou = f\"copy_{i}_{imatge_original}\"\n",
    "    ruta_origen = os.path.join(dir_no_defecte, imatge_original)\n",
    "    ruta_desti = os.path.join(dir_no_defecte, nom_nou)\n",
    "    shutil.copy(ruta_origen, ruta_desti)\n",
    "\n",
    "print(f\"Imatges duplicades: {n_extra}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(\"dataset_job1\", output=\"dataset\",\n",
    "                   seed=1337, ratio=(.8, .2), move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set:\")\n",
    "print(\"defect -\", len(os.listdir(\"dataset/train/1_defecte\")))  \n",
    "print(\"nodefect -\", len(os.listdir(\"dataset/train/0_nodefecte\")))\n",
    "print(\"Validation set:\")\n",
    "print(\"defect -\", len(os.listdir(\"dataset/val/1_defecte\")))\n",
    "print(\"nodefect -\", len(os.listdir(\"dataset/val/0_nodefecte\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fbc2b",
   "metadata": {},
   "source": [
    "### 2. Augmentació de les imatges\n",
    "Per millorar la capacitat de generalització del model, augmentem les imatges amb rotacions aleatòries. Això ajuda a millorar el rendiment en la classificació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7085a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset/train\"\n",
    "\n",
    "angles = [90, 180, -90]       \n",
    "augment_per_class = 495\n",
    "\n",
    "def augmentar_classe(cls_dir, n_noves):\n",
    "    originals = [f for f in os.listdir(cls_dir)\n",
    "                 if not f.startswith('rot') and f.lower().endswith(('.jpg'))]\n",
    "    generades = 0\n",
    "    while generades < n_noves:\n",
    "        nom_orig = random.choice(originals)\n",
    "        ruta_orig = os.path.join(cls_dir, nom_orig)\n",
    "\n",
    "        img = Image.open(ruta_orig)\n",
    "        angle = random.choice(angles)\n",
    "        img_rot = img.rotate(angle, expand=True)\n",
    "\n",
    "        base, ext = os.path.splitext(nom_orig)\n",
    "        nou_nom = f\"{base}_rot{angle}_{generades}{ext.lower()}\"\n",
    "        img_rot.save(os.path.join(cls_dir, nou_nom))\n",
    "        generades += 1\n",
    "\n",
    "    print(f\"{os.path.basename(cls_dir)}: {generades} imatges creades\")\n",
    "\n",
    "classes = os.listdir(train_dir)\n",
    "\n",
    "for cls in classes:\n",
    "    augmentar_classe(os.path.join(train_dir, cls), augment_per_class)\n",
    "\n",
    "print(\"Fet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ab82d",
   "metadata": {},
   "source": [
    "### 3. Creació dels Generadors de Dades\n",
    "Utilitzem ImageDataGenerator per generar dades augmentades de les imatges d'entrenament i validació. També aplicarem la funció de pre-processament adequada per als models InceptionV3 i MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8056e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_generadors(dataset_path, target_size, preprocess_func):\n",
    "    gen_train = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "    gen_val = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "\n",
    "    train_data = gen_train.flow_from_directory(\n",
    "        os.path.join(dataset_path, \"train\"),\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\"\n",
    "    )\n",
    "\n",
    "    val_data = gen_val.flow_from_directory(\n",
    "        os.path.join(dataset_path, \"val\"),\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_data, val_data\n",
    "\n",
    "def train_model(base_model, optimizer, model_name, train_data, val_data, epochs=50):\n",
    "    base_model.trainable = False\n",
    "    # definir model\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    # configurar model\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "    # entrenar model\n",
    "    history = model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=[early_stop])\n",
    "    model.save(f\"{model_name}.h5\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e9ae9",
   "metadata": {},
   "source": [
    "## 4. Entrenament del Model\n",
    "Per entrenar els models utilitzem les xarxes preentrenades InceptionV3 i MobileNetV2. Els models tenen una finestra de paciència de 3 epochs per evitar l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e229ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/\"\n",
    "# Model 1 - InceptionV3\n",
    "inceptionv3 =  applications.InceptionV3(include_top=False, input_shape=(299, 299, 3), weights=\"imagenet\")\n",
    "train_data_i, val_data_i = crear_generadors(dataset_path, target_size=(299, 299), preprocess_func=preprocess_incep)\n",
    "model_incepv3, history_incepv3 = train_model(inceptionv3, RMSprop(learning_rate=0.0001), \"model_inceptionv3_50\", train_data_i, val_data_i)\n",
    "\n",
    "# Model 2 - MobileNetV2\n",
    "mobilenetv2 = applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "train_data_m, val_data_m = crear_generadors(dataset_path, target_size=(224, 224), preprocess_func=preprocess_mobile)\n",
    "model_mobilenetv2, history_mobilenetv2 = train_model(mobilenetv2, Adam(learning_rate=0.0001), \"model_mobilenetv2_50\", train_data_m, val_data_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e8d37",
   "metadata": {},
   "source": [
    "### 5. Avaluació del Model\n",
    "Després de l'entrenament, avaluem el rendiment dels models utilitzant les mètriques de precisió i pèrdua tant per al conjunt d'entrenament com de validació. També analitzem el comportament dels models utilitzant diferents llindars de classificació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_histories = [\n",
    "    (\"MobileNetV2\", history_mobilenetv2),\n",
    "    (\"InceptionV3\", history_incepv3)\n",
    "]\n",
    "\n",
    "for model_name, history in model_histories:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # Gràfica de precisió\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Gràfica de pèrdua\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_thresholds(model, val_data, model_name, thresholds=[0.2, 0.3, 0.4, 0.5]):\n",
    "    probs = model.predict(val_data)\n",
    "    true_labels = val_data.classes[:len(probs)]\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = (probs > threshold).astype(int).flatten()\n",
    "        print(f\"\\nClassificació per llindar {threshold} - {model_name}:\")\n",
    "        print(classification_report(true_labels, preds, target_names=val_data.class_indexs.keys()))\n",
    "\n",
    "        cm = confusion_matrix(true_labels, preds)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=val_data.class_indexs.keys(),\n",
    "                    yticklabels=val_data.class_indexs.keys())\n",
    "        plt.title(f\"Matriu de confusió - {model_name} (llindar: {threshold})\")\n",
    "        plt.ylabel(\"Etiqueta real\")\n",
    "        plt.xlabel(\"Predicció\")\n",
    "        plt.show()\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "evaluate_model_thresholds(model_incepv3, val_data_i, \"InceptionV3\", thresholds)\n",
    "evaluate_model_thresholds(model_mobilenetv2, val_data_m, \"MobileNetV2\", thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928a916",
   "metadata": {},
   "source": [
    "### 6. Visualització d'Errors\n",
    "Visualitzem els errors (falsos positius i falsos negatius) per diferents llindars per entendre millor el comportament dels models en situacions d'error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_per_thresholds(model, val_data, class_indexs, thresholds=[0.2, 0.3, 0.4, 0.5], max_mostres=10):\n",
    "    true_labels = val_data.classes\n",
    "    class_names = list(class_indexs.keys())\n",
    "    probs = model.predict(val_data, verbose=0)\n",
    "    file_paths = val_data.filepaths\n",
    "    idx_to_class = {v: k for k, v in class_indexs.items()}\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = (probs > threshold).astype(int).flatten()\n",
    "        fp_indexs = np.where((preds == 1) & (true_labels == 0))[0]\n",
    "        fn_indexs = np.where((preds == 0) & (true_labels == 1))[0]\n",
    "\n",
    "        print(f\"\\nLlindar: {threshold}\")\n",
    "\n",
    "        def mostrar_muestras(indexs, titol):\n",
    "            print(f\"\\n{titol} ({len(indexs)} mostres):\")\n",
    "            for i in indexs[:max_mostres]:\n",
    "                img_path = file_paths[i]\n",
    "                img = plt.imread(img_path)\n",
    "                base_name = os.path.basename(img_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(f\"{base_name}\\nReal: {idx_to_class[true_labels[i]]} | Predicció: {idx_to_class[preds[i]]}\")\n",
    "                plt.show()\n",
    "\n",
    "        mostrar_muestras(fp_indexs, \"Falsos positius (Prediu 'defecte', era 'nodefecte')\")\n",
    "        mostrar_muestras(fn_indexs, \"Falsos negatius (Prediu 'nodefecte', era 'defecte')\")\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "print(\"\\nErrors InceptionV3:\")\n",
    "errors_per_thresholds(model_incepv3, val_data_i, val_data_i.class_indexs, thresholds)\n",
    "\n",
    "print(\"\\nErrors MobileNetV2:\")\n",
    "errors_per_thresholds(model_mobilenetv2, val_data_m, val_data_m.class_indexs, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51fa12",
   "metadata": {},
   "source": [
    "### 7. Predicció i visualització de resultats\n",
    "Finalment, es poden visualitzar les prediccions del model sobre un conjunt d'imatges de validació, juntament amb la confiança en la predicció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"InceptionV3\": load_model(\"model_inceptionv3_50.h5\")}\n",
    "\n",
    "class_indexs = {v: k for k, v in val_data_i.class_indexs.items()}\n",
    "\n",
    "mostrar_img = 30\n",
    "lote_test, etiquetes_reals = next(val_data_i)\n",
    "\n",
    "for i in range(min(mostrar_img, len(lote_test))):\n",
    "    plt.imshow(lote_test[i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    img_array = np.expand_dims(lote_test[i], axis=0)\n",
    "\n",
    "    for nombre, model in models.items():\n",
    "        prob = float(model.predict(img_array, verbose=0)[0][0])\n",
    "        classe_pred = int(prob >= 0.3)\n",
    "        nom_classe_pred = class_indexs[classe_pred]\n",
    "        nom_classe_real = class_indexs[int(etiquetes_reals[i])]\n",
    "        confiança = prob if classe_pred == 1 else 1 - prob\n",
    "\n",
    "        print(f\"{nombre}: Predicció → {nom_classe_pred} (Confiança: {confiança * 100:.2f}%) | Real: {nom_classe_real}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
